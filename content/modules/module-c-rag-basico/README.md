# M√≥dulo C: RAG B√°sico con Citas

## üéØ Objetivos de Aprendizaje

Al completar este m√≥dulo, ser√°s capaz de:

1. **Implementar RAG b√°sico** con algoritmos BM25 y TF-IDF
2. **Generar citas can√≥nicas** en formato `uri#Lx-Ly`
3. **Aplicar t√©cnicas de re-ranking** usando Maximal Marginal Relevance (MMR)
4. **Integrar RAG con agentes** del m√≥dulo anterior
5. **Manejar documentos estructurados** y metadatos

---

## üìö 1. Introducci√≥n a RAG

### 1.1 ¬øQu√© es Retrieval-Augmented Generation?

RAG es un patr√≥n arquitect√≥nico que combina:

- **Retrieval**: B√∫squeda en base de conocimiento
- **Augmentation**: Enriquecimiento del contexto  
- **Generation**: Generaci√≥n de respuestas con LLM

```
Usuario ‚Üí Consulta ‚Üí [RETRIEVAL] ‚Üí Documentos ‚Üí [AUGMENTATION] ‚Üí Contexto ‚Üí [GENERATION] ‚Üí Respuesta
```

### 1.2 Ventajas del RAG

| Ventaja | Descripci√≥n | Ejemplo |
|---------|-------------|---------|
| **Actualizaci√≥n** | Informaci√≥n siempre actualizada | Documentaci√≥n t√©cnica |
| **Precisi√≥n** | Respuestas basadas en fuentes | Citaci√≥n de documentos |
| **Control** | Fuentes conocidas y verificables | Pol√≠ticas empresariales |
| **Eficiencia** | Sin re-entrenamiento de modelos | Cambios en productos |

### 1.3 Arquitectura RAG B√°sica

```python
class BasicRAG:
    def __init__(self):
        self.document_store = DocumentStore()      # Almac√©n de documentos
        self.retriever = Retriever()              # Motor de b√∫squeda
        self.ranker = Ranker()                    # Re-ranking por relevancia
        self.generator = Generator()              # LLM para respuestas
    
    def query(self, question: str) -> str:
        # 1. RETRIEVAL: Buscar documentos relevantes
        candidates = self.retriever.search(question)
        
        # 2. RANKING: Ordenar por relevancia
        ranked_docs = self.ranker.rank(question, candidates)
        
        # 3. AUGMENTATION: Preparar contexto
        context = self._build_context(ranked_docs)
        
        # 4. GENERATION: Generar respuesta
        response = self.generator.generate(question, context)
        
        return response
```

---

## üîç 2. Algoritmos de B√∫squeda

### 2.1 TF-IDF (Term Frequency - Inverse Document Frequency)

**Concepto:** Mide la importancia de un t√©rmino en un documento relativo a una colecci√≥n.

**F√≥rmula:**
```
TF-IDF(t,d) = TF(t,d) √ó IDF(t)
TF(t,d) = (frecuencia de t en d) / (total t√©rminos en d)
IDF(t) = log(N / df(t))
```

**Implementaci√≥n b√°sica:**
```python
import math
from collections import Counter
from typing import List, Dict

class TFIDFRetriever:
    def __init__(self, documents: List[str]):
        self.documents = documents
        self.vocab = self._build_vocabulary()
        self.idf_scores = self._compute_idf()
        self.doc_vectors = self._compute_doc_vectors()
    
    def _build_vocabulary(self) -> set:
        """Construir vocabulario √∫nico"""
        vocab = set()
        for doc in self.documents:
            vocab.update(doc.lower().split())
        return vocab
    
    def _compute_idf(self) -> Dict[str, float]:
        """Calcular IDF para cada t√©rmino"""
        idf_scores = {}
        N = len(self.documents)
        
        for term in self.vocab:
            df = sum(1 for doc in self.documents if term in doc.lower())
            idf_scores[term] = math.log(N / max(df, 1))
        
        return idf_scores
    
    def search(self, query: str, top_k: int = 5) -> List[tuple]:
        """Buscar documentos m√°s relevantes"""
        query_vector = self._compute_query_vector(query)
        scores = []
        
        for i, doc_vector in enumerate(self.doc_vectors):
            score = self._cosine_similarity(query_vector, doc_vector)
            scores.append((i, score))
        
        # Ordenar por score descendente
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]
```

### 2.2 BM25 (Best Matching 25)

**Concepto:** Mejora de TF-IDF que considera longitud del documento y saturaci√≥n de t√©rminos.

**F√≥rmula:**
```
BM25(q,d) = Œ£ IDF(qi) √ó (tf(qi,d) √ó (k1 + 1)) / (tf(qi,d) + k1 √ó (1 - b + b √ó |d|/avgdl))
```

**Par√°metros:**
- `k1`: Controla saturaci√≥n de t√©rminos (t√≠picamente 1.2-2.0)
- `b`: Controla impacto de longitud de documento (t√≠picamente 0.75)

**Implementaci√≥n:**
```python
class BM25Retriever:
    def __init__(self, documents: List[str], k1: float = 1.5, b: float = 0.75):
        self.documents = documents
        self.k1 = k1
        self.b = b
        self.avgdl = sum(len(doc.split()) for doc in documents) / len(documents)
        self.doc_freqs = []
        self.idf = {}
        self._initialize()
    
    def _initialize(self):
        """Inicializar frecuencias e IDF"""
        df = {}  # document frequency
        
        for doc in self.documents:
            tokens = doc.lower().split()
            freq = Counter(tokens)
            self.doc_freqs.append(freq)
            
            for token in freq.keys():
                df[token] = df.get(token, 0) + 1
        
        # Calcular IDF
        N = len(self.documents)
        for token, freq in df.items():
            self.idf[token] = math.log((N - freq + 0.5) / (freq + 0.5))
    
    def search(self, query: str, top_k: int = 5) -> List[tuple]:
        """Buscar con BM25"""
        query_tokens = query.lower().split()
        scores = []
        
        for i, doc_freq in enumerate(self.doc_freqs):
            score = 0
            doc_len = sum(doc_freq.values())
            
            for token in query_tokens:
                if token in doc_freq:
                    tf = doc_freq[token]
                    idf = self.idf.get(token, 0)
                    
                    # BM25 score para este t√©rmino
                    numerator = tf * (self.k1 + 1)
                    denominator = tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl)
                    score += idf * (numerator / denominator)
            
            scores.append((i, score))
        
        scores.sort(key=lambda x: x[1], reverse=True)
        return scores[:top_k]
```

---

## üìñ 3. Sistema de Citas Can√≥nicas

### 3.1 Formato de Citas

**Estructura:** `uri#Lx-Ly`
- `uri`: Identificador √∫nico del documento
- `Lx`: L√≠nea de inicio
- `Ly`: L√≠nea de fin

**Ejemplos:**
```
doc://manual-python.md#L45-L52
https://docs.python.org/tutorial#L120-L125
file://policies/security.pdf#L8-L15
```

### 3.2 Generaci√≥n de Citas

```python
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class Citation:
    """Cita can√≥nica con metadatos"""
    uri: str
    start_line: int
    end_line: int
    content: str
    relevance_score: float
    metadata: Dict[str, Any]
    
    def to_canonical(self) -> str:
        """Generar cita en formato can√≥nico"""
        return f"{self.uri}#L{self.start_line}-L{self.end_line}"
    
    def __str__(self) -> str:
        return f"[{self.to_canonical()}] {self.content[:100]}..."

class CitationGenerator:
    """Generador de citas can√≥nicas"""
    
    def __init__(self, line_context: int = 2):
        self.line_context = line_context
    
    def generate_citation(self, 
                         document_uri: str,
                         content: str,
                         match_start: int,
                         match_end: int,
                         score: float,
                         metadata: Dict = None) -> Citation:
        """
        Generar cita con contexto de l√≠neas
        
        Args:
            document_uri: URI del documento
            content: Contenido completo del documento
            match_start: Posici√≥n inicial del match
            match_end: Posici√≥n final del match  
            score: Score de relevancia
            metadata: Metadatos adicionales
        """
        lines = content.split('\n')
        
        # Encontrar l√≠neas del match
        current_pos = 0
        start_line = 1
        end_line = 1
        
        for i, line in enumerate(lines):
            line_end = current_pos + len(line) + 1  # +1 por \n
            
            if current_pos <= match_start < line_end:
                start_line = i + 1
            
            if current_pos <= match_end <= line_end:
                end_line = i + 1
                break
                
            current_pos = line_end
        
        # Agregar contexto
        context_start = max(1, start_line - self.line_context)
        context_end = min(len(lines), end_line + self.line_context)
        
        # Extraer contenido citado
        cited_content = '\n'.join(lines[context_start-1:context_end])
        
        return Citation(
            uri=document_uri,
            start_line=context_start,
            end_line=context_end,
            content=cited_content,
            relevance_score=score,
            metadata=metadata or {}
        )
```

### 3.3 Validaci√≥n de Citas

```python
import re

class CitationValidator:
    """Validador de citas can√≥nicas"""
    
    CITATION_PATTERN = re.compile(r'^([^#]+)#L(\d+)-L(\d+)$')
    
    @classmethod
    def validate_format(cls, citation: str) -> tuple[bool, str]:
        """Validar formato de cita can√≥nica"""
        match = cls.CITATION_PATTERN.match(citation)
        
        if not match:
            return False, "Formato inv√°lido. Debe ser: uri#Lx-Ly"
        
        uri, start_line, end_line = match.groups()
        start_line, end_line = int(start_line), int(end_line)
        
        if start_line > end_line:
            return False, "L√≠nea inicial no puede ser mayor que l√≠nea final"
        
        if start_line < 1:
            return False, "N√∫meros de l√≠nea deben ser >= 1"
        
        return True, "Formato v√°lido"
    
    @classmethod
    def parse_citation(cls, citation: str) -> Optional[tuple]:
        """Parsear cita can√≥nica"""
        match = cls.CITATION_PATTERN.match(citation)
        if match:
            uri, start_line, end_line = match.groups()
            return uri, int(start_line), int(end_line)
        return None
```

---

## üîÑ 4. Re-ranking con MMR

### 4.1 Maximal Marginal Relevance

**Objetivo:** Balancear relevancia con diversidad para evitar documentos redundantes.

**F√≥rmula:**
```
MMR = Œª √ó Sim(q, d) - (1-Œª) √ó max Sim(d, d')
```
- `Œª`: Par√°metro de balance (0-1)
- `Sim(q, d)`: Similaridad consulta-documento
- `Sim(d, d')`: Similaridad entre documentos ya seleccionados

### 4.2 Implementaci√≥n MMR

```python
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class MMRRanker:
    """Re-ranker usando Maximal Marginal Relevance"""
    
    def __init__(self, lambda_param: float = 0.7):
        self.lambda_param = lambda_param
        self.vectorizer = TfidfVectorizer(stop_words='english')
    
    def rank(self, 
             query: str, 
             documents: List[str], 
             top_k: int = 5) -> List[int]:
        """
        Re-rankear documentos usando MMR
        
        Args:
            query: Consulta del usuario
            documents: Lista de documentos candidatos
            top_k: N√∫mero de documentos a retornar
            
        Returns:
            Lista de √≠ndices de documentos rankeados
        """
        if not documents:
            return []
        
        # Vectorizar consulta y documentos
        all_texts = [query] + documents
        vectors = self.vectorizer.fit_transform(all_texts)
        
        query_vector = vectors[0]
        doc_vectors = vectors[1:]
        
        # Calcular similaridades consulta-documento
        query_similarities = cosine_similarity(query_vector, doc_vectors)[0]
        
        # MMR iterativo
        selected_indices = []
        remaining_indices = list(range(len(documents)))
        
        for _ in range(min(top_k, len(documents))):
            best_score = -float('inf')
            best_idx = None
            
            for idx in remaining_indices:
                # Relevancia con la consulta
                relevance = query_similarities[idx]
                
                # M√°xima similaridad con documentos ya seleccionados
                if selected_indices:
                    selected_vectors = doc_vectors[selected_indices]
                    current_vector = doc_vectors[idx:idx+1]
                    max_similarity = cosine_similarity(current_vector, selected_vectors).max()
                else:
                    max_similarity = 0
                
                # Score MMR
                mmr_score = (self.lambda_param * relevance - 
                           (1 - self.lambda_param) * max_similarity)
                
                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = idx
            
            if best_idx is not None:
                selected_indices.append(best_idx)
                remaining_indices.remove(best_idx)
        
        return selected_indices
```

---

## üóÉÔ∏è 5. Almac√©n de Documentos

### 5.1 Estructura de Documentos

```python
@dataclass
class Document:
    """Documento con metadatos"""
    id: str
    uri: str
    title: str
    content: str
    author: Optional[str] = None
    created_at: Optional[datetime] = None
    tags: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def get_lines(self) -> List[str]:
        """Obtener l√≠neas del documento"""
        return self.content.split('\n')
    
    def extract_snippet(self, start_line: int, end_line: int) -> str:
        """Extraer snippet por l√≠neas"""
        lines = self.get_lines()
        snippet_lines = lines[start_line-1:end_line]
        return '\n'.join(snippet_lines)

class DocumentStore:
    """Almac√©n de documentos con √≠ndices"""
    
    def __init__(self):
        self.documents: Dict[str, Document] = {}
        self.uri_index: Dict[str, str] = {}  # uri -> doc_id
        self.tag_index: Dict[str, List[str]] = {}  # tag -> [doc_ids]
    
    def add_document(self, document: Document) -> None:
        """Agregar documento al almac√©n"""
        self.documents[document.id] = document
        self.uri_index[document.uri] = document.id
        
        # Indexar por tags
        for tag in document.tags:
            if tag not in self.tag_index:
                self.tag_index[tag] = []
            self.tag_index[tag].append(document.id)
    
    def get_by_id(self, doc_id: str) -> Optional[Document]:
        """Obtener documento por ID"""
        return self.documents.get(doc_id)
    
    def get_by_uri(self, uri: str) -> Optional[Document]:
        """Obtener documento por URI"""
        doc_id = self.uri_index.get(uri)
        return self.documents.get(doc_id) if doc_id else None
    
    def search_by_tags(self, tags: List[str]) -> List[Document]:
        """Buscar documentos por tags"""
        doc_ids = set()
        for tag in tags:
            if tag in self.tag_index:
                doc_ids.update(self.tag_index[tag])
        
        return [self.documents[doc_id] for doc_id in doc_ids]
    
    def get_all_documents(self) -> List[Document]:
        """Obtener todos los documentos"""
        return list(self.documents.values())
```

---

## üîß 6. Laboratorio Pr√°ctico

### 6.1 Ejercicio 1: Implementar Retriever B√°sico ‚úÖ

**Objetivo:** Crear retriever con TF-IDF y BM25

**Archivo:** `labs/module-c/basic_retriever.py`

**Estado**: ‚úÖ **COMPLETADO** - TFIDFRetriever y BM25Retriever funcionales con preprocessor avanzado

```python
# ‚úÖ IMPLEMENTADO: BasicRetriever que:
# 1. ‚úÖ Soporta TF-IDF y BM25 con par√°metros configurables
# 2. ‚úÖ Maneja documentos estructurados con metadatos
# 3. ‚úÖ Genera scores de relevancia precisos
# 4. ‚úÖ Permite configuraci√≥n de par√°metros (k1, b para BM25)
```

### 6.2 Ejercicio 2: Sistema de Citas ‚úÖ

**Objetivo:** Implementar generaci√≥n y validaci√≥n de citas can√≥nicas

**Archivo:** `labs/module-c/citation_system.py`

**Estado**: ‚úÖ **COMPLETADO** - Sistema completo de citas con validaci√≥n estricta y generaci√≥n autom√°tica

```python
# ‚úÖ IMPLEMENTADO: CitationSystem que:
# 1. ‚úÖ Genera citas en formato uri#Lx-Ly con contexto
# 2. ‚úÖ Valida formato con regex patterns estrictos
# 3. ‚úÖ Maneja contexto de l√≠neas autom√°ticamente
# 4. ‚úÖ Extrae snippets citados con validaci√≥n de consistencia
```

### 6.3 Ejercicio 3: RAG Completo ‚úÖ

**Objetivo:** Integrar retrieval, ranking y generaci√≥n

**Archivo:** `labs/module-c/complete_rag.py`

**Estado**: ‚úÖ **COMPLETADO** - Pipeline RAG completo con MMR, generaci√≥n inteligente e integraci√≥n con agente PEC

```python
# ‚úÖ IMPLEMENTADO: CompleteRAG que:
# 1. ‚úÖ Combina retriever + MMR ranker + response generator
# 2. ‚úÖ Usa MMR para re-ranking y diversidad de resultados
# 3. ‚úÖ Genera respuestas con citas can√≥nicas autom√°ticas
# 4. ‚úÖ Integra con agente PEC del m√≥dulo B como herramienta
```

---

## üìä 7. Casos de Uso Reales

### 7.1 Documentaci√≥n T√©cnica

```python
# Ejemplo: RAG para documentaci√≥n de API
docs = [
    "La funci√≥n authenticate() valida credenciales de usuario...",
    "El endpoint /api/users retorna lista de usuarios activos...",
    "Para autorizaci√≥n usa headers Authorization: Bearer <token>..."
]

retriever = BM25Retriever(docs)
results = retriever.search("c√≥mo autenticar usuario", top_k=2)

# Resultado: [(0, 0.85), (2, 0.72)]
# Con citas: doc://api-docs.md#L15-L18, doc://api-docs.md#L45-L47
```

### 7.2 Base de Conocimiento Empresarial

```python
# Ejemplo: Pol√≠ticas de empresa
policy_docs = [
    "Las vacaciones deben solicitarse con 15 d√≠as de anticipaci√≥n...",
    "El trabajo remoto requiere aprobaci√≥n del supervisor directo...",
    "Los gastos de viaje deben incluir recibos originales..."
]

# Con MMR para diversidad de respuestas
ranker = MMRRanker(lambda_param=0.8)
ranked_results = ranker.rank("pol√≠tica de trabajo remoto", policy_docs)
```

### 7.3 Soporte T√©cnico

```python
# Ejemplo: Troubleshooting autom√°tico
trouble_docs = [
    "Error 404: Verificar URL y permisos de acceso...",
    "Conexi√≥n lenta: Revisar configuraci√≥n de red...", 
    "Login fallido: Confirmar credenciales y estado de cuenta..."
]

# Pipeline completo RAG
rag_system = CompleteRAG()
response = rag_system.query("no puedo hacer login")
# Respuesta incluye citas a documentos relevantes
```

---

## üéØ 8. M√©tricas de Evaluaci√≥n

### 8.1 M√©tricas de Retrieval

| M√©trica | Descripci√≥n | F√≥rmula |
|---------|-------------|---------|
| **Precision@k** | % relevantes en top-k | relevantes_recuperados / k |
| **Recall@k** | % del total relevante recuperado | relevantes_recuperados / total_relevantes |
| **MRR** | Mean Reciprocal Rank | 1/N √ó Œ£(1/rank_primer_relevante) |
| **NDCG@k** | Normalized Discounted Cumulative Gain | DCG@k / IDCG@k |

### 8.2 M√©tricas de Generaci√≥n

| M√©trica | Descripci√≥n | Uso |
|---------|-------------|-----|
| **BLEU** | Overlap de n-gramas con referencia | Traducci√≥n autom√°tica |
| **ROUGE** | Overlap de tokens con referencia | Resumen autom√°tico |
| **BERTScore** | Similaridad sem√°ntica con embeddings | Evaluaci√≥n general |
| **Factualidad** | % claims verificables en fuentes | RAG espec√≠fico |

### 8.3 Implementaci√≥n de Evaluaci√≥n

```python
class RAGEvaluator:
    """Evaluador espec√≠fico para sistemas RAG"""
    
    def evaluate_retrieval(self, 
                          queries: List[str],
                          true_relevant: List[List[str]],
                          retrieved: List[List[str]]) -> Dict[str, float]:
        """Evaluar calidad del retrieval"""
        metrics = {}
        
        # Precision@k promedio
        precisions = []
        for relevant, retr in zip(true_relevant, retrieved):
            relevant_set = set(relevant)
            retrieved_set = set(retr)
            precision = len(relevant_set & retrieved_set) / len(retrieved_set)
            precisions.append(precision)
        
        metrics['precision_at_k'] = sum(precisions) / len(precisions)
        
        return metrics
    
    def evaluate_citations(self, 
                          generated_citations: List[str],
                          source_documents: List[str]) -> Dict[str, float]:
        """Evaluar calidad de las citas"""
        valid_citations = 0
        total_citations = len(generated_citations)
        
        for citation in generated_citations:
            if self._is_citation_valid(citation, source_documents):
                valid_citations += 1
        
        return {
            'citation_accuracy': valid_citations / total_citations,
            'total_citations': total_citations
        }
```

---

## üöÄ 9. Optimizaciones Avanzadas

### 9.1 Cache de Embeddings

```python
import pickle
from functools import lru_cache

class CachedRetriever:
    """Retriever con cache de embeddings"""
    
    def __init__(self, cache_file: str = "embeddings.pkl"):
        self.cache_file = cache_file
        self.embedding_cache = self._load_cache()
    
    @lru_cache(maxsize=1000)
    def get_embedding(self, text: str) -> np.ndarray:
        """Obtener embedding con cache"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        # Generar embedding (simulado)
        embedding = np.random.random(384)  # Simular embedding
        self.embedding_cache[text] = embedding
        return embedding
    
    def save_cache(self):
        """Guardar cache en disco"""
        with open(self.cache_file, 'wb') as f:
            pickle.dump(self.embedding_cache, f)
```

### 9.2 √çndices Aproximados

```python
import faiss
import numpy as np

class FaissRetriever:
    """Retriever usando FAISS para b√∫squeda aproximada"""
    
    def __init__(self, dimension: int = 384):
        self.dimension = dimension
        self.index = faiss.IndexFlatIP(dimension)  # Inner Product
        self.doc_ids = []
    
    def add_documents(self, embeddings: np.ndarray, doc_ids: List[str]):
        """Agregar documentos al √≠ndice"""
        self.index.add(embeddings.astype('float32'))
        self.doc_ids.extend(doc_ids)
    
    def search(self, query_embedding: np.ndarray, top_k: int = 5) -> List[tuple]:
        """B√∫squeda aproximada con FAISS"""
        scores, indices = self.index.search(
            query_embedding.astype('float32').reshape(1, -1), 
            top_k
        )
        
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < len(self.doc_ids):
                results.append((self.doc_ids[idx], float(score)))
        
        return results
```

---

## üìà 10. Pr√≥ximos Pasos

### 10.1 Conexi√≥n con M√≥dulo D

El M√≥dulo C establece la base para evaluaci√≥n en el M√≥dulo D:
- M√©tricas de retrieval (Precision@k, Recall@k)
- Evaluaci√≥n de calidad de citas
- Benchmarks de latencia y throughput

### 10.2 Preparaci√≥n para Capstone

Los componentes RAG ser√°n integrados en el proyecto final:
- Agente PEC (M√≥dulo B) + RAG (M√≥dulo C)
- Sistema completo de Q&A con citas
- Dashboard de evaluaci√≥n (M√≥dulo D)

---

## ‚úÖ Resumen del M√≥dulo

Al completar este m√≥dulo habr√°s implementado:

1. **Retriever b√°sico** con TF-IDF y BM25
2. **Sistema de citas can√≥nicas** con formato `uri#Lx-Ly`
3. **Re-ranking con MMR** para diversidad de resultados
4. **Almac√©n de documentos** con √≠ndices y metadatos
5. **Pipeline RAG completo** integrado con agentes

**Tiempo estimado:** 3-4 horas  
**Prerrequisitos:** M√≥dulos A y B completados  
**Siguiente:** M√≥dulo D - M√©tricas y Evaluaci√≥n
